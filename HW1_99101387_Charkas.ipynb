{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0bed29",
   "metadata": {},
   "source": [
    "# Soraya charkas 99101387"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39333b57",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb90ecc",
   "metadata": {},
   "source": [
    "A Hebbian neuron is a type of artificial neuron inspired by the Hebbian theory of learning, which states that when two neurons are activated simultaneously, the strength of the connection between them is strengthened. In other words, \"neurons that fire together, wire together.\"\n",
    "In the context of artificial neural networks, a Hebbian neuron is a neuron that modifies the strength of its connections to other neurons based on the activation patterns of those neurons. Specifically, when the output of a Hebbian neuron is high, it increases the strength of its connections to the neurons that contributed to that output, and when the output is low, it decreases the strength of those connections.\n",
    "Hebbian neurons can be used in multi-layer neural networks, but they are typically used only in the input layer, where they modify the weights of the connections between the input neurons and the neurons in the next layer. In deeper layers of the network, other types of neurons, such as sigmoid or rectified linear units (ReLU), are more commonly used. This is because Hebbian learning can lead to instability and overfitting in deeper layers due to the \"exploding gradient\" problem, where the weights become so large that the network becomes unstable and cannot learn effectively.\n",
    "Therefore, while Hebbian neurons can be used in multi-layer models, they are typically used only in the input layer and other types of neurons are used in the deeper layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f680a8d",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de8bbc",
   "metadata": {},
   "source": [
    "When the patterns in Hebbian learning are orthogonal, we expect the learning to be more efficient and the resulting representations to be more distinct and separable.\n",
    "In Hebbian learning, the strength of the connection between two neurons is modified based on the co-activation of those neurons. If the patterns are orthogonal, meaning that they are mutually exclusive and have no overlap, the neurons will be activated independently and thus their connections will be modified independently. This means that the connections between neurons that correspond to different patterns will be strengthened, while connections between neurons that correspond to similar patterns will be weakened or unchanged. orthogonal patterns can also reduce the problem of interference in the learning process. Interference occurs when learning one pattern disrupts the learned representation of another pattern. Since orthogonal patterns are mutually exclusive, learning one pattern does not interfere with the learned representation of another pattern, making the learning process more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b250e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary packages\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a6a5a",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32354a9d",
   "metadata": {},
   "source": [
    "first, we define the \"Hebbian_learning\" function and the \"output\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0e0e8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necesary functions\n",
    "def Hebbian_learning(weights, word, target):\n",
    "    target_vec = np.zeros(7)\n",
    "    target_vec[target] = 1\n",
    "    weights[0:7, 0:35] += np.outer(target_vec, word)\n",
    "    weights[7, 0] += 1\n",
    "    return weights\n",
    "## -------------------------------\n",
    "def Train(weights, word):\n",
    "    weights_no_bias = weights[:, :35]\n",
    "    activations = np.matmul(weights_no_bias, word.T)\n",
    "    result = (activations >= weights[7, 0]).astype(float)\n",
    "    return result.T\n",
    "## -------------------------------\n",
    "def Train2(weights , word): \n",
    "    result = np.zeros((1,7) , dtype = float)\n",
    "    for i in range (7):\n",
    "        act = np.matmul(weights [i , 0:35] , word)\n",
    "        if act >= weights [7][0] :\n",
    "            result [0][i] = 1\n",
    "        else :\n",
    "            result [0][i] = -1\n",
    "    return result\n",
    "## -------------------------------\n",
    "def Binary_Polar(char):\n",
    "    for i in range (7):\n",
    "        for j in range (3):\n",
    "            for k in range (35):\n",
    "                if (char[i][j][k] == 0):\n",
    "                    char[i][j][k] = -1\n",
    "    return char\n",
    "## -------------------------------\n",
    "def Hebbian_learning_2(weights, word, target):\n",
    "    for i in range(7):\n",
    "        if i == target:\n",
    "            weights[i, 0:35] += word\n",
    "            weights[7][0] += 1\n",
    "        else:\n",
    "            weights[i, 0:35] -= word\n",
    "            weights[7][0] -= 1\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb1a7b",
   "metadata": {},
   "source": [
    "here,we define our patterns and tests for letters A,X,O,E,Z,T,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "090ea1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = np.zeros((7,3,35),dtype=float )\n",
    "# Define the patterns for character A\n",
    "pattern[0,0,:]= [0,0,1,0,0,0,1,0,1,0,1,1,1,1,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1]\n",
    "\n",
    "pattern[0,1,:]= [0,0,1,0,0,0,1,0,1,0,1,1,1,1,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0]\n",
    "\n",
    "pattern[0,2,:]= [0,1,1,1,0,1,0,0,0,1,1,0,0,0,0,1,1,1,1,0,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0]\n",
    "\n",
    "# Define the patterns for character X\n",
    "pattern[1,0,:]= [1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0]\n",
    "\n",
    "pattern[1,1,:]= [1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,1,1,1,1,1,0,0,0,0,0]\n",
    "\n",
    "pattern[1,2,:]= [1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,1,1,1,1,1]\n",
    "# Define the patterns for character O\n",
    "pattern[3,0,:]= [0,1,1,1,0,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "pattern[3,1,:]= [0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "pattern[3,2,:]= [0,0,1,1,0,0,1,0,0,1,1,0,0,0,1,1,0,0,0,1,0,1,0,0,1,0,0,1,1,0,0,0,0,0,0]\n",
    "# Define the patterns for character L\n",
    "pattern[4,0,:]= [1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "pattern[4,1,:]= [1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,0,1,1]\n",
    "\n",
    "pattern[4,2,:]= [1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,1,1,0]\n",
    "\n",
    "# Define the patterns for character T\n",
    "pattern[5,0,:]= [1,1,1,1,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0]\n",
    "\n",
    "pattern[5,1,:]= [1,1,1,1,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "pattern[5,2,:]= [1,1,1,1,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0]\n",
    "\n",
    "# Define the patterns for character Z\n",
    "pattern[6,0,:]= [1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "pattern[6,1,:]= [1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,1,1,1,1,0]\n",
    "\n",
    "pattern[6,2,:]= [1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# Define the patterns for character E\n",
    "\n",
    "pattern[2,0,:]= [1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "pattern[2,1,:]= [1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,0,0,0]\n",
    "\n",
    "pattern[2,2,:]=[1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,0]\n",
    "\n",
    "\n",
    "\n",
    "patternTest = np.zeros((7,3,35),dtype=float )\n",
    "# Define the testing patterns for character A\n",
    "patternTest[0,1,:] = [0,0,1,0,0,0,1,0,1,0,1,1,0,1,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,0]\n",
    "\n",
    "patternTest[0,0,:] = [0,0,1,0,0,0,1,0,1,0,1,0,1,1,1,1,0,0,0,1,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0]\n",
    "\n",
    "# Define the testing patterns for character X\n",
    "patternTest[1,0,:] = [1,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,0]\n",
    "\n",
    "patternTest[1,1,:] = [1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,0,0]\n",
    "\n",
    "\n",
    "# Define the patterns for character O\n",
    "patternTest[2,0,:] = [0,1,1,1,0,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "patternTest[2,1,:] = [0,0,0,0,0,0,1,0,1,0,1,0,0,0,1,1,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# Define the testing patterns for character L\n",
    "patternTest[3,0,:] =[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,1,0,1]\n",
    "\n",
    "patternTest[3,1,:] = [1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,0,0,1]\n",
    "    \n",
    "# Define the patterns for character T\n",
    "patternTest[4,0,:] = [1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0]\n",
    "\n",
    "patternTest[4,1,:] = [1,1,1,1,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# Define the testing patterns for character Z\n",
    "patternTest[5,0,:] = [1,1,1,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "patternTest[5,1,:] = [1,0,0,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,1,1,1,1,0]\n",
    "\n",
    "# Define the patterns for character E\n",
    "\n",
    "patternTest[6,0,:] = [1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,0,0,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1]\n",
    "\n",
    "patternTest[6,1,:] = [1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,0,1,1,0,0,0,0,0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa805284",
   "metadata": {},
   "source": [
    "using the written function, we now train our neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1baf98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((8 , 35) , dtype = float) \n",
    "for i, j in np.ndindex((7, 3)):\n",
    "    Hebbian_learning(weights, pattern[i, j, :], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "de93c927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 1. 1. 0. 0. 0. 0. 1.]\n",
      "  [0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [1. 1. 1. 0. 1. 0. 1. 1.]\n",
      "  [1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "  [1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "  [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "  [0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "  [0. 0. 1. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(3):\n",
    "        print(\" \",Train(weights , pattern[i,j,:]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4b19b",
   "metadata": {},
   "source": [
    "It is evident that the correct answer was obtained at A2-L1-L2. Prior to examination, it was observed that 'L' would be a suitable selection due to its orthogonality with a majority of the characters.The error rate is found to be considerably high, with an accuracy of only 14.28%, indicating poor performance of the algorithm. Random selection of words would result in an accuracy of approximately 13.5%, revealing the inadequacy of the algorithm.in this case, we examined our algorithm using the patterns we train it,lets see what happens if we use different patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e241442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "  [0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "  [1. 0. 1. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(2):\n",
    "        print(\" \",Train(weights , patternTest[i,j,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8129d58",
   "metadata": {},
   "source": [
    "Upon utilizing various patterns, the accuracy of the classification dropped to a third of the original value, declining from 14.28% to 4.7%. This indicates that the use of the Hebbian algorithm for learning is not effective, and that successful classification is not achieved. While the algorithm is able to correctly identify the target word in some cases, it indiscriminately groups together other words in the classification process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7733fd",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae4c24",
   "metadata": {},
   "source": [
    "we have to define a new training function.it is visible to you in the first cell named \"Train2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "437da9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((8 , 35) , dtype = float) \n",
    "for i, j in np.ndindex((7, 3)):\n",
    "    Hebbian_learning(weights, pattern[i, j, :], i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c6f2d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [[ 1. -1.  1. -1. -1. -1. -1.]]\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[ 1. -1.  1. -1. -1. -1. -1.]]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1.  1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1.  1. -1. -1. -1.  1.]]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [[ 1.  1.  1. -1.  1. -1.  1.]]\n",
      "  [[ 1.  1.  1. -1. -1. -1.  1.]]\n",
      "  [[ 1. -1.  1. -1.  1. -1.  1.]]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [[-1. -1.  1.  1. -1. -1. -1.]]\n",
      "  [[-1. -1. -1.  1. -1. -1. -1.]]\n",
      "  [[-1. -1. -1.  1. -1. -1. -1.]]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1. -1.  1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "  [[-1. -1.  1. -1. -1.  1. -1.]]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1. -1. -1.  1.]]\n",
      "  [[-1. -1.  1. -1. -1. -1.  1.]]\n",
      "  [[-1. -1.  1. -1. -1. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(3):\n",
    "        print(\" \",Train2(weights , pattern[i,j,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd9289",
   "metadata": {},
   "source": [
    "as we expected,the results are the same as our first examination.lets try it out with new patters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33de6973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[ 1. -1.  1. -1. -1. -1. -1.]]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [[-1. -1.  1.  1. -1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1. -1. -1.  1.]]\n",
      "  [[-1. -1.  1. -1. -1. -1.  1.]]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [[ 1. -1.  1. -1.  1. -1.  1.]]\n",
      "  [[ 1. -1.  1. -1. -1. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(2):\n",
    "        print(\" \",Train2(weights , patternTest[i,j,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614dff1",
   "metadata": {},
   "source": [
    "The application of the bipolar algorithm yielded a superior outcome, with 5 out of 14 characters being accurately detected, resulting in an accuracy of 35.7%, a significant improvement from the previous results. The character 'T' exhibited the optimal response, attributed to its orthogonality with the remaining characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5020a",
   "metadata": {},
   "source": [
    "now,we convert our patterns to bipolar form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8d53a355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[ 1. -1. -1.  1. -1. -1. -1.]]\n",
      "  [[ 1. -1.  1. -1. -1. -1. -1.]]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1. -1. -1.  1. -1.  1.]]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1. -1.  1.]]\n",
      "  [[-1. -1.  1. -1. -1. -1. -1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1.  1.]]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [[-1. -1. -1.  1. -1. -1. -1.]]\n",
      "  [[ 1. -1. -1.  1. -1. -1. -1.]]\n",
      "  [[ 1. -1. -1.  1. -1. -1. -1.]]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1. -1.  1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1.  1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1.  1.]]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1.  1.  1.]]\n",
      "  [[-1. -1.  1. -1.  1.  1.  1.]]\n",
      "  [[-1. -1. -1.  1. -1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "pattern=Binary_Polar(pattern)\n",
    "weights = np.zeros((8 , 35) , dtype = float) \n",
    "for i, j in np.ndindex((7, 3)):\n",
    "    Hebbian_learning(weights, pattern[i, j, :], i)\n",
    "    \n",
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(3):\n",
    "        print(\" \",Train2(weights , pattern[i,j,:]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d823a8",
   "metadata": {},
   "source": [
    "Upon examination, the algorithm was found to detect 6 out of 21 characters, indicating an accuracy rate of 42.8%. Implementing the bipolar form resulted in an improved outcome, aligning with our expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5f642",
   "metadata": {},
   "source": [
    "and for noisy pattern we have :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fc5369ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1.  1. -1. -1.]]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1. -1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1. -1.  1.]]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1. -1. -1. -1.]]\n",
      "  [[-1. -1.  1. -1. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(2):\n",
    "        print(\" \",Train2(weights , patternTest[i,j,:]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299df02c",
   "metadata": {},
   "source": [
    "the result is shocking!we got 9 out of 14 algorithms correct which is nearly 65% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be783ee",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff873f",
   "metadata": {},
   "source": [
    "The results were derived from the preceding sections, indicating an accuracy of 4.7% for binary input, 35% for binary input in the bipolar model, and 65% for bipolar input and output. As anticipated, the bipolar form demonstrated superior performance, exhibiting resilience in the presence of noisy input, surpassing the performance of other algorithms.Overall, the Hebbian algorithms exhibit little variation in performance between noisy and non-noisy input, with outputs showing minimal deviation. This resilience to noise highlights the algorithm's robustness against interference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad033ba",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "360a59c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [[1. 1. 1. 1. 1. 1. 1.]]\n",
      "  [[1. 1. 1. 1. 1. 1. 1.]]\n",
      "  [[ 1. -1.  1.  1.  1. -1. -1.]]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [[1. 1. 1. 1. 1. 1. 1.]]\n",
      "  [[1. 1. 1. 1. 1. 1. 1.]]\n",
      "  [[ 1.  1.  1. -1.  1.  1.  1.]]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1. -1.  1.]]\n",
      "  [[ 1. -1.  1. -1.  1.  1. -1.]]\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [[ 1. -1.  1.  1.  1.  1.  1.]]\n",
      "  [[ 1.  1. -1.  1.  1.  1.  1.]]\n",
      "  [[1. 1. 1. 1. 1. 1. 1.]]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1.  1. -1. -1.]]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1.  1.  1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "weights = np.zeros((8 , 35) , dtype = float) \n",
    "for i, j in np.ndindex((7, 3)):\n",
    "    Hebbian_learning_2(weights, pattern[i, j, :], i)\n",
    "    \n",
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(3):\n",
    "        print(\" \",Train2(weights , pattern[i,j,:]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e23c0",
   "metadata": {},
   "source": [
    "and for the noisy input we have :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3a9dc5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0\n",
      "_____________________________\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[ 1. -1. -1. -1. -1. -1. -1.]]\n",
      "pattern 1\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1.  1. -1. -1. -1. -1. -1.]]\n",
      "pattern 2\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1. -1. -1.]]\n",
      "pattern 3\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1.  1. -1. -1.]]\n",
      "  [[-1. -1. -1. -1.  1. -1. -1.]]\n",
      "pattern 4\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "  [[-1. -1. -1. -1. -1.  1. -1.]]\n",
      "pattern 5\n",
      "_____________________________\n",
      "  [[-1. -1. -1. -1. -1. -1.  1.]]\n",
      "  [[-1. -1. -1. -1. -1. -1.  1.]]\n",
      "pattern 6\n",
      "_____________________________\n",
      "  [[-1. -1.  1. -1. -1. -1. -1.]]\n",
      "  [[-1. -1.  1. -1. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"pattern \" + str(i))\n",
    "    print(\"_____________________________\")\n",
    "    for j in range(2):\n",
    "        print(\" \",Train2(weights , patternTest[i,j,:]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88f6ae",
   "metadata": {},
   "source": [
    "The results obtained in this section demonstrate an improvement in responses. Notably, as anticipated, the characters 'L' and 'T' exhibit notably superior performance, as evidenced in the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb02b91",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0676a",
   "metadata": {},
   "source": [
    "As previously noted, the expected improvement in response occurs when the letters are orthogonal to each other. For instance, the Hebbian neuron is unlikely to distinguish between 'E' and 'A', whereas 'T' and 'L' are completely orthogonal, thereby facilitating recognition of these characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95c069",
   "metadata": {},
   "source": [
    "Utilizing both the letters 'L' and 'T', we observed the most optimal responses from these characters, in line with our expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ce4f3",
   "metadata": {},
   "source": [
    "Although the Hebbian neuron may not be the most efficient approach for character recognition, it serves as a commendable initial step in the field of neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
